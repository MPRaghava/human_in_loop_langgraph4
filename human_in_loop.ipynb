{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3c4aadc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import Graph,MessagesState,StateGraph,END,START\n",
    "from langchain_core.messages import HumanMessage,SystemMessage\n",
    "from langgraph.prebuilt import tools_condition\n",
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "from IPython.display import Image,display\n",
    "from typing import TypedDict,Annotated,Sequence\n",
    "import operator,json\n",
    "from langchain_core.messages import BaseMessage\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_community.tools import DuckDuckGoSearchRun\n",
    "from langchain.tools import tool\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67043e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "groq_key = os.getenv(\"groq_api_key\")\n",
    "llm = ChatGroq(model_name =\"gemma2-9b-it\", api_key=groq_key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "620de42d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello! ðŸ‘‹  How can I help you today? ðŸ˜Š\\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 11, 'total_tokens': 26, 'completion_time': 0.027272727, 'prompt_time': 0.001899597, 'queue_time': 0.24918127199999998, 'total_time': 0.029172324}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run--7725c519-4ca7-4788-af14-1d4c05790082-0', usage_metadata={'input_tokens': 11, 'output_tokens': 15, 'total_tokens': 26})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c7e8fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def multiply(first_number: int, second_number : int)->int:\n",
    "    \"\"\" Multiply two integers\"\"\"\n",
    "    return first_number * second_number\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b6ac45e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# multiply({\"first_number\":12,\"second_number\":2})\n",
    "# multiply.invoke({\"first_number\":12,\"second_number\":3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28beef5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @tool\n",
    "# def search(query:str):\n",
    "#     \"\"\"Perform the web search on the user query\"\"\"\n",
    "#     tavily = TavilySearchResults()\n",
    "#     result = tavily.invoke(query)\n",
    "#     return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7c28eac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def search(query:str):\n",
    "    \"\"\" Search web based on the user query\"\"\"\n",
    "    dgdgs = DuckDuckGoSearchRun()\n",
    "    result = dgdgs.invoke(query)\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7b0feddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# search(\"who is the current president of the USA?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4a34225b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [search,multiply]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cfebf65",
   "metadata": {},
   "source": [
    "<!-- retrieving function names and arguments for tool name and question -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "be46cba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_with_tools = llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "be88cf83",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_mapping = {tool.name :tool for tool in tools}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8380d8c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'search': StructuredTool(name='search', description='Search web based on the user query', args_schema=<class 'langchain_core.utils.pydantic.search'>, func=<function search at 0x0000022F3084F420>),\n",
       " 'multiply': StructuredTool(name='multiply', description='Multiply two integers', args_schema=<class 'langchain_core.utils.pydantic.multiply'>, func=<function multiply at 0x0000022F2E6199E0>)}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "027aadc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = model_with_tools.invoke(\"who is Indian current  prime minister?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b726acc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_details = response.additional_kwargs.get(\"tool_calls\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e36b3ca8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 'call_esea',\n",
       "  'function': {'arguments': '{\"query\":\"who is the current prime minister of India\"}',\n",
       "   'name': 'search'},\n",
       "  'type': 'function'}]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "778c99c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'search'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_details[0][\"function\"][\"name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c232ad02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"query\":\"who is the current prime minister of India\"}'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_details[0][\"function\"][\"arguments\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "81b66007",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "    message: Annotated[Sequence[BaseMessage],operator.add]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "57461951",
   "metadata": {},
   "outputs": [],
   "source": [
    "def invoke_model(state:AgentState):\n",
    "    messages = state[\"messages\"]\n",
    "    question = messages[-1] ## fetching the usr question\n",
    "    return {\"messages\":[model_with_tools.invoke(question)]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3a6d6a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def invoke_tool(state: AgentState):\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a1997737",
   "metadata": {},
   "outputs": [],
   "source": [
    "def router(state):\n",
    "    tool_calls = state['messages'][-1].additional_kwargs.get(\"tool_calls\",[])\n",
    "    if len(tool_calls):\n",
    "        return \"tool\"\n",
    "    else:\n",
    "        return \"end\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "09a9bd14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x22f30f24d10>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph = StateGraph(AgentState)\n",
    "\n",
    "graph.add_node(\"ai_assistant\",invoke_model)\n",
    "graph.add_node(\"tool\",invoke_tool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "73b4450e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x22f30f24d10>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.add_conditional_edges(\"ai_assistant\",router,{\"tool\":tool,\"end\":END,})\n",
    "graph.add_edge(\"tool\",END)\n",
    "graph.set_entry_point(\"ai_assistant\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2a7d2d57",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "At 'ai_assistant' node, 'router' branch found unknown target '<function tool at 0x0000022F25EF6480>'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[47]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mgraph\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompile\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Admin\\LLM\\Agentic AI\\human_in_loop_langgraph4\\.venv\\Lib\\site-packages\\langgraph\\graph\\state.py:592\u001b[39m, in \u001b[36mStateGraph.compile\u001b[39m\u001b[34m(self, checkpointer, store, interrupt_before, interrupt_after, debug, name)\u001b[39m\n\u001b[32m    589\u001b[39m interrupt_after = interrupt_after \u001b[38;5;129;01mor\u001b[39;00m []\n\u001b[32m    591\u001b[39m \u001b[38;5;66;03m# validate the graph\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m592\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mvalidate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    593\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    594\u001b[39m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m \u001b[49m\u001b[43m!=\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m*\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43minterrupt_after\u001b[49m\n\u001b[32m    595\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m \u001b[49m\u001b[43m!=\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m*\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m    596\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m    597\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    598\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    600\u001b[39m \u001b[38;5;66;03m# prepare output channels\u001b[39;00m\n\u001b[32m    601\u001b[39m output_channels = (\n\u001b[32m    602\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m__root__\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    603\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.schemas[\u001b[38;5;28mself\u001b[39m.output]) == \u001b[32m1\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    609\u001b[39m     ]\n\u001b[32m    610\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Admin\\LLM\\Agentic AI\\human_in_loop_langgraph4\\.venv\\Lib\\site-packages\\langgraph\\graph\\graph.py:288\u001b[39m, in \u001b[36mGraph.validate\u001b[39m\u001b[34m(self, interrupt)\u001b[39m\n\u001b[32m    286\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m end \u001b[38;5;129;01min\u001b[39;00m branch.ends.values():\n\u001b[32m    287\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m end \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.nodes \u001b[38;5;129;01mand\u001b[39;00m end != END:\n\u001b[32m--> \u001b[39m\u001b[32m288\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    289\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mAt \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstart\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m node, \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcond\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m branch found unknown target \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mend\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    290\u001b[39m             )\n\u001b[32m    291\u001b[39m         all_targets.add(end)\n\u001b[32m    292\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mValueError\u001b[39m: At 'ai_assistant' node, 'router' branch found unknown target '<function tool at 0x0000022F25EF6480>'"
     ]
    }
   ],
   "source": [
    "graph.compile()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
